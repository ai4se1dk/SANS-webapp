---
phase: 02-core-sync
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - tests/test_sync_flow.py
autonomous: true

must_haves:
  truths:
    - "Integration tests exist for SYNC-01 (set-model state synchronization)"
    - "Integration tests exist for SYNC-02 (set-parameter widget synchronization)"
    - "Integration tests exist for SYNC-03 (set-multiple-parameters atomic updates)"
    - "All sync tests pass"
  artifacts:
    - path: "tests/test_sync_flow.py"
      provides: "Integration tests for MCP tool -> UI sync"
      contains: "test_set_model_updates_session_state"
    - path: "tests/test_sync_flow.py"
      provides: "Integration tests for parameter sync"
      contains: "test_set_parameter_updates_widget_state"
    - path: "tests/test_sync_flow.py"
      provides: "Integration tests for batch updates"
      contains: "test_set_multiple_parameters_atomic"
---

<objective>
Verify that the sync infrastructure from Phase 1 works correctly by writing integration tests for each SYNC requirement.

Purpose: Phase 1 implemented all the sync infrastructure (bridge methods, tool refactoring, needs_rerun flag). Phase 2 verifies it works end-to-end by testing the complete flow from tool execution to session state updates.

Output:
- tests/test_sync_flow.py with integration tests for SYNC-01, SYNC-02, SYNC-03
- All tests passing
</objective>

<execution_context>
@C:\Users\piotrrozyczko\.claude/get-shit-done/workflows/execute-plan.md
@C:\Users\piotrrozyczko\.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02-core-sync/02-RESEARCH.md

# Key source files to understand
@src/sans_webapp/services/mcp_state_bridge.py
@src/sans_webapp/mcp_server.py
@tests/test_mcp_tools.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create integration tests for SYNC-01 (set-model)</name>
  <files>tests/test_sync_flow.py</files>
  <action>
Create a new test file `tests/test_sync_flow.py` with tests for SYNC-01 requirement.

The tests should verify that when `set_model()` is called:
1. `st.session_state.current_model` is set to the new model name
2. `st.session_state.model_selected` is set to True
3. `st.session_state.fit_completed` is set to False
4. `st.session_state.needs_rerun` is set to True
5. Old parameter widget keys are cleared

Use the existing MockSessionState pattern from test_mcp_tools.py and patch `sans_webapp.services.mcp_state_bridge.st`.

Test structure:
```python
"""
Integration tests for MCP tool -> UI state synchronization.

Tests the complete sync flow: tool execution -> bridge state update -> session_state.
"""

import pytest
from unittest.mock import MagicMock, patch


class MockSessionState:
    """Mock for Streamlit session_state with full dict-like behavior."""

    def __init__(self):
        self._data = {
            'ai_tools_enabled': True,
            'needs_rerun': False,
            'current_model': None,
            'model_selected': False,
            'fit_completed': False,
        }

    # ... implement __getattr__, __setattr__, __getitem__, __setitem__, get, __contains__, keys, __delitem__


class MockFitter:
    """Mock for SANSFitter."""
    # ... reuse from test_mcp_tools.py


class TestSyncSetModel:
    """Test SYNC-01: set-model tool state synchronization."""

    def test_set_model_updates_current_model(self, mock_fitter, mock_session_state):
        """set-model should update st.session_state.current_model."""
        ...

    def test_set_model_sets_model_selected_flag(self, mock_fitter, mock_session_state):
        """set-model should set model_selected to True."""
        ...

    def test_set_model_clears_fit_completed(self, mock_fitter, mock_session_state):
        """set-model should reset fit_completed to False."""
        ...

    def test_set_model_sets_needs_rerun(self, mock_fitter, mock_session_state):
        """set-model should set needs_rerun to True for UI refresh."""
        ...

    def test_set_model_clears_old_parameter_widgets(self, mock_fitter, mock_session_state):
        """set-model should clear old parameter widget keys."""
        ...
```
  </action>
  <verify>
Run: `python -m pytest tests/test_sync_flow.py::TestSyncSetModel -v`
All tests should pass.
  </verify>
  <done>
tests/test_sync_flow.py created with TestSyncSetModel class containing 5 tests for SYNC-01. All tests pass.
  </done>
</task>

<task type="auto">
  <name>Task 2: Add integration tests for SYNC-02 (set-parameter)</name>
  <files>tests/test_sync_flow.py</files>
  <action>
Add tests for SYNC-02 requirement to tests/test_sync_flow.py.

The tests should verify that when `set_parameter()` is called:
1. `st.session_state['value_{name}']` is updated with the clamped value
2. `st.session_state['min_{name}']` is updated when min_bound provided
3. `st.session_state['max_{name}']` is updated when max_bound provided
4. `st.session_state['vary_{name}']` is updated when vary provided
5. `st.session_state.needs_rerun` is set to True

Test structure:
```python
class TestSyncSetParameter:
    """Test SYNC-02: set-parameter tool widget synchronization."""

    def test_set_parameter_updates_value_widget(self, mock_fitter, mock_session_state):
        """set-parameter should update value_{name} in session_state."""
        ...

    def test_set_parameter_updates_min_widget(self, mock_fitter, mock_session_state):
        """set-parameter should update min_{name} when min_bound provided."""
        ...

    def test_set_parameter_updates_max_widget(self, mock_fitter, mock_session_state):
        """set-parameter should update max_{name} when max_bound provided."""
        ...

    def test_set_parameter_updates_vary_widget(self, mock_fitter, mock_session_state):
        """set-parameter should update vary_{name} when vary provided."""
        ...

    def test_set_parameter_sets_needs_rerun(self, mock_fitter, mock_session_state):
        """set-parameter should set needs_rerun for UI refresh."""
        ...
```
  </action>
  <verify>
Run: `python -m pytest tests/test_sync_flow.py::TestSyncSetParameter -v`
All tests should pass.
  </verify>
  <done>
TestSyncSetParameter class added with 5 tests for SYNC-02. All tests pass.
  </done>
</task>

<task type="auto">
  <name>Task 3: Add integration tests for SYNC-03 (set-multiple-parameters)</name>
  <files>tests/test_sync_flow.py</files>
  <action>
Add tests for SYNC-03 requirement to tests/test_sync_flow.py.

The tests should verify that when `set_multiple_parameters()` is called:
1. All specified parameter values are updated in session_state
2. All specified bounds are updated in session_state
3. All specified vary flags are updated in session_state
4. Updates happen atomically (single needs_rerun at end)
5. Parameters not in the dict are not modified

Test structure:
```python
class TestSyncSetMultipleParameters:
    """Test SYNC-03: set-multiple-parameters atomic updates."""

    def test_set_multiple_parameters_updates_all_values(self, mock_fitter, mock_session_state):
        """set-multiple-parameters should update all specified values."""
        ...

    def test_set_multiple_parameters_updates_bounds(self, mock_fitter, mock_session_state):
        """set-multiple-parameters should update bounds for all specified."""
        ...

    def test_set_multiple_parameters_updates_vary_flags(self, mock_fitter, mock_session_state):
        """set-multiple-parameters should update vary flags for all specified."""
        ...

    def test_set_multiple_parameters_single_rerun(self, mock_fitter, mock_session_state):
        """set-multiple-parameters should set needs_rerun once at end."""
        ...

    def test_set_multiple_parameters_leaves_unspecified_unchanged(self, mock_fitter, mock_session_state):
        """set-multiple-parameters should not modify unspecified parameters."""
        ...
```
  </action>
  <verify>
Run: `python -m pytest tests/test_sync_flow.py::TestSyncSetMultipleParameters -v`
All tests should pass.
  </verify>
  <done>
TestSyncSetMultipleParameters class added with 5 tests for SYNC-03. All tests pass.
  </done>
</task>

<task type="auto">
  <name>Task 4: Run full test suite to verify no regressions</name>
  <files>tests/test_sync_flow.py</files>
  <action>
Run the complete test suite to ensure:
1. All new sync flow tests pass
2. No regressions in existing tests
3. Total test count increased by ~15 tests

Commands:
```bash
# Run all sync flow tests
python -m pytest tests/test_sync_flow.py -v

# Run full test suite
python -m pytest tests/ -v --tb=short
```

If any tests fail, fix them before marking complete.
  </action>
  <verify>
Run: `python -m pytest tests/ --tb=short`
All tests should pass. Total should be ~129 tests (114 original + 15 new).
  </verify>
  <done>
Full test suite passes. New tests for SYNC-01, SYNC-02, SYNC-03 integrated successfully.
  </done>
</task>

</tasks>

<verification>
After all tasks complete, verify the full integration:

1. **New test file exists:**
   ```bash
   ls tests/test_sync_flow.py
   ```

2. **Test count verification:**
   ```bash
   python -m pytest tests/test_sync_flow.py --collect-only | grep "test session starts"
   ```
   Expected: ~15 tests collected

3. **All tests pass:**
   ```bash
   python -m pytest tests/ -v --tb=short | tail -20
   ```
   Expected: All pass, no failures

4. **Code style check:**
   ```bash
   ruff check tests/test_sync_flow.py
   ```
</verification>

<success_criteria>
1. tests/test_sync_flow.py exists with integration tests for all SYNC requirements
2. TestSyncSetModel class has 5+ tests for SYNC-01
3. TestSyncSetParameter class has 5+ tests for SYNC-02
4. TestSyncSetMultipleParameters class has 5+ tests for SYNC-03
5. All new tests pass
6. No regressions in existing 114 tests
7. Code passes ruff linting
</success_criteria>

<output>
After completion, create `.planning/phases/02-core-sync/02-01-SUMMARY.md`
</output>
